{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31442a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c908cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c9123",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15985677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Check shape of dataset â€” Understand rows/columns count â†’ Helps estimate dataset size.\n",
    "def explore_shapes(df)->None:\n",
    "    shapes = df.shape\n",
    "    print(f\"rows : {shapes[0]}\")\n",
    "    print(f\"columns : {shapes[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f4cdfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. List all columns and data types â€” Identify numeric, categorical, date, and text features â†’ Plan preprocessing.\n",
    "def explore_types(df) -> dict:\n",
    "    types = df.dtypes.value_counts().to_dict()\n",
    "    for i,k in types.items():\n",
    "        print(f\"Total {k} of column type : {i}\")\n",
    "    type_to_column = {}\n",
    "    for i,k in types.items():\n",
    "        type_to_column[str(i)] = df.select_dtypes(include=[i]).columns.tolist()\n",
    "    return type_to_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ee5796d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Check null or missing values â€” Detect data quality issues â†’ Plan imputation/removal.\n",
    "def explore_null_or_missing(df:pd.DataFrame, type_to_column : dict)->tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "        Analyze and summarize missing (null) values in a dataset at both the *column level*\n",
    "        âš™ï¸ **Parameters**\n",
    "        ----------------------------------------------------------------------------\n",
    "        df : pd.DataFrame  \n",
    "            The input DataFrame to analyze. It should already be cleaned of any \n",
    "            structural issues (e.g., duplicated column names).\n",
    "\n",
    "        type_to_column : dict  \n",
    "            A mapping between logical data types and their corresponding columns.\n",
    "            Typically derived from schema understanding or auto-detection.\n",
    "\n",
    "            Example:\n",
    "            ```\n",
    "            {\n",
    "                'numeric': ['age', 'salary', 'income'],\n",
    "                'categorical': ['gender', 'city', 'profession'],\n",
    "                'datetime': ['joining_date', 'exit_date']\n",
    "            }\n",
    "            ```\n",
    "        ----------------------------------------------------------------------------\n",
    "        ðŸ“¤ **Returns**\n",
    "        ----------------------------------------------------------------------------\n",
    "            tuple[pd.DataFrame, pd.DataFrame]\n",
    "            Returns two summary DataFrames at column type level and column level:\n",
    "\n",
    "    \"\"\"\n",
    "    numberOfRecord = len(df)\n",
    "    columnLevelSummary = []\n",
    "    typeLevelSummary = []\n",
    "    for t, collist in type_to_column.items():\n",
    "        numberOfcolumns = len(collist)\n",
    "        missing = df[collist].isnull().sum()\n",
    "        missing = missing[missing> 0]\n",
    "        if len(missing) > 0:\n",
    "            missing = missing.to_dict()\n",
    "            typeLevelSummary.append({\"column_type\" : t, \"column_with_missing_values\" : len(missing), \"total_columns\" : numberOfcolumns, \"percentage\" : round(len(missing)/numberOfcolumns * 100, 2)})\n",
    "            for col,v in missing.items():\n",
    "                columnLevelSummary.append({\"column_type\" : t, \"column\" : col, \"missing_record\" : v, \"total_record\" : numberOfRecord, \"percentage\" : round(v/numberOfRecord * 100, 2)})\n",
    "\n",
    "\n",
    "    typeLevelSummary = pd.DataFrame(typeLevelSummary)\n",
    "    columnLevelSummary = pd.DataFrame(columnLevelSummary)\n",
    "    return typeLevelSummary, columnLevelSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "17ed3764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Check duplicate rows â€” Identify redundancy â†’ Clean data.\n",
    "def explore_duplicates(df : pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    isduplicate = df.duplicated().any()\n",
    "    if isduplicate:\n",
    "        print(f\"Number of Duplicate records -> {df.duplicated().sum()}\")\n",
    "    else:\n",
    "        print(\"No duplicate records Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "45c0aeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows : 1460\n",
      "columns : 81\n",
      "Total 43 of column type : object\n",
      "Total 35 of column type : int64\n",
      "Total 3 of column type : float64\n",
      "No duplicate records Found\n"
     ]
    }
   ],
   "source": [
    "explore_shapes(df)\n",
    "type_to_column = explore_types(df)\n",
    "typeLevelSummary, columnLevelSummary = explore_null_or_missing(df, type_to_column)\n",
    "explore_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Check unique values per column â€” Understand feature variety â†’ Find categorical vs continuous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "950890e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.any of 0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "1455    False\n",
       "1456    False\n",
       "1457    False\n",
       "1458    False\n",
       "1459    False\n",
       "Length: 1460, dtype: bool>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5b623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf3b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "House_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
